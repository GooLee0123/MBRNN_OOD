[Training]
# string
method=unsup
noise=noise

# boolean

train=False
; if True, train else evaluate.

# integer
gpuid=0
batch_size=1024
lr_decay_epoch=10
ts2_patience=10
ts3_patience=20
; start fine-tuning as the number of consecutive epochs
; without improvement exceeds the patience
max_training_epoch=100

# float
gamma=0.0
; anchor loss gamma
dcp_margin=4.1
; discrepancy loss margin

[Input]
ind=galaxy
bin_dn=./bin_edges
data_dn=./data

ncls=64

[Output]
out_fn=zphot.npy
ckpt_dn=Checkpoints
quant_dn=Quantities
output_dn=./Outputs

[Network]
optim=adam
widening_layer=128,256,512,1024
narrowing_layer=512,256,128,32
; network structure will be [widening_layer + narrowing_layer]

[Verbose]
pevery=50
; print training-related infromation every given epoch
vevery=200
; print validation-related infromation every given epoch

[Logs]
log_level=info
; verbose level
