[Training]
# string
method=unsup
noise=noise

# boolean

train=False
; if True, train else evaluate.
finetune=True
; if True, fine-tune the model for ood detection

# integer
gpuid=0
batch_size=1024
lr_decay_epoch=10
finetune_patience=10
posttune_patience=20
; start fine-tuning as the number of consecutive epochs
; without improvement exceeds the patience
max_training_epoch=100

# float
nu=0.5
; power of noise
gamma=0.0
; anchor loss gamma
dcp_margin=4.1
; discrepancy loss margin
dcp_weight=1.0
; learning rate for fine tuning
finetune_lr=0.0008

[Input]
ind=galaxy
bin_dn=./bin_edges
data_dn=../OOD_detection_main/data_processed
tr_ul_prefix=RA_combined_usample
ul_prefix=RA_combined

ncls=64

[Output]
out_fn=zphot.npy
plot_dn=Plots
ckpt_dn=Checkpoints
loss_dn=Losses
quant_dn=Quantities
analysis_dn=./Analysis

[Network]
ecase=case2
optim=adam
widening_layer=128,256,512,1024
narrowing_layer=512,256,128,32
; network structure will be [widening_layer + narrowing_layer]

pdrop=0.5

[Verbose]
pevery=50
; print training-related infromation every given epoch
vevery=200
; print validation-related infromation every given epoch

[Logs]
log_level=info
; verbose level
